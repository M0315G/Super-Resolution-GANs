{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "data_dir = \"<Path to the dataset>\"\n",
    "model_dir = \"<Path to the folder to store the model>\"\n",
    "output_dir = \"<Path for the generated images>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image\n",
    "down_scale = 4             # downsampling scale\n",
    "cropped_width = 204        # high res image (width)\n",
    "cropped_height = 64     # high res image (height)\n",
    "image_shape = (64, 204, 3)# high res image (shape)\n",
    "\n",
    "# TRAIN\n",
    "num_images = 2364          # total number of images (train & test)\n",
    "split_ratio = 0.8\n",
    "epochs = 1000\n",
    "batch_size = 32\n",
    "learning_rate = 1e-4\n",
    "epsilon = 1e-8\n",
    "sample_every = 1\n",
    "save_every = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def down_sample(img, scale=down_scale):\n",
    "    \n",
    "    new_h = img.shape[0]//scale\n",
    "    new_w = img.shape[1]//scale\n",
    "    lr_image = np.asarray(Image.fromarray(np.uint8(img)).resize((new_w, new_h), Image.BICUBIC))\n",
    "    return lr_image\n",
    "\n",
    "\n",
    "def normalize(img):\n",
    "    n_img = np.divide(img.astype(np.float32), 127.5) - np.ones_like(img, dtype=np.float32)\n",
    "    return n_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "hr_images = []\n",
    "lr_images = []\n",
    "\n",
    "def get_data(data_dir = data_dir):\n",
    "    \n",
    "    for img_name in glob.glob(data_dir+\"*.png\"):\n",
    "        hr_img = cv2.imread(os.path.join(img_name), cv2.IMREAD_COLOR)\n",
    "        lr_img = down_sample(hr_img)\n",
    "        hr_images.append(hr_img)\n",
    "        lr_images.append(lr_img)\n",
    "        \n",
    "        \n",
    "get_data()\n",
    "hr_images = np.array(hr_images)\n",
    "lr_images = np.array(lr_images)\n",
    "print(\"High resolution image dataset shape: \", np.shape(hr_images))\n",
    "print(\"Low resolution image dataset shape: \", np.shape(lr_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilty Function for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_data(data_dir = data_dir, num_img=num_images,\n",
    "                   split_ration=split_ratio,\n",
    "                   hr_images=hr_images, lr_images=lr_images):\n",
    "    \n",
    "    num_train = int(num_img*split_ratio)\n",
    "    \n",
    "    hr_images = [normalize(img) for img in hr_images]\n",
    "    lr_images = [normalize(img) for img in lr_images]\n",
    "    \n",
    "    hr_images = np.array(hr_images)\n",
    "    lr_images = np.array(lr_images)\n",
    "    hr_train = np.array(hr_images[:num_train,:,:,:])\n",
    "    hr_test = np.array(hr_images[num_train:,:,:,:])\n",
    "    lr_train = np.array(lr_images[:num_train,:,:,:])\n",
    "    lr_test = np.array(lr_images[num_train:,:,:,:])\n",
    "    \n",
    "    return hr_train, hr_test, lr_train, lr_test\n",
    "\n",
    "hr_train, hr_test, lr_train, lr_test = load_train_data()\n",
    "print(\"HR images training dataset shape: \", np.shape(hr_train), \"\\t\")\n",
    "print(\"LR images training dataset shape: \", np.shape(lr_train), \"\\t\")\n",
    "print(\"HR images test dataset shape: \", np.shape(hr_test), \"\\t\")\n",
    "print(\"LR images test dataset shape: \", np.shape(lr_test), \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.core import Activation, Flatten\n",
    "from keras.layers import Input, add, LeakyReLU, PReLU\n",
    "from keras.layers import BatchNormalization, Conv2D, UpSampling2D, Dense\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(model, kernel, filters, strides):\n",
    "    \"\"\"Residual block inspired by SRResNet.\n",
    "       In -> Conv -> BN -> PReLU -> Conv -> BN -> add -> Out\n",
    "       |___________________________________________^ \n",
    "    \"\"\"\n",
    "    prev = model\n",
    "    \n",
    "    model = Conv2D(filters=filters, kernel_size=kernel, strides=strides, padding=\"same\")(model)\n",
    "    model = BatchNormalization(momentum=0.5)(model)\n",
    "    model = PReLU(alpha_initializer=\"zeros\", alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(model)\n",
    "    model = Conv2D(filters=filters, kernel_size=kernel, strides=strides, padding=\"same\")(model)\n",
    "    model = BatchNormalization(momentum=0.5)(model)\n",
    "    \n",
    "    model = add([prev, model])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def up_sample_block(model, kernel, filters, strides):\n",
    "    \"\"\"Up sampling block (can be replaced by Conv2DTranspose layer).\n",
    "       In -> Conv -> UpSample -> LReLU -> Out\n",
    "    \"\"\"\n",
    "    \n",
    "    model = Conv2D(filters=filters, kernel_size = kernel, strides = strides, padding=\"same\")(model)\n",
    "    model = UpSampling2D()(model)\n",
    "    model = LeakyReLU(0.2)(model)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator_NN():\n",
    "    \n",
    "    \"\"\"The Generator Network.\n",
    "        Input -> Conv -> PReLU -> Res x 16 -> Conv -> BN -> add -> UpSample x 2 -> Conv -> Tanh -> Output\n",
    "                           |_________________________________^\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, noise_shape):\n",
    "        self.noise_shape = noise_shape\n",
    "        \n",
    "    def generator(self):\n",
    "        \n",
    "        g_input = Input(shape=self.noise_shape)\n",
    "        model = Conv2D(filters=64, kernel_size=9, strides=1, padding=\"same\")(g_input)\n",
    "        model = PReLU(alpha_initializer=\"zeros\", alpha_regularizer=None,\n",
    "                     alpha_constraint=None, shared_axes=[1,2])(model)\n",
    "        prev = model\n",
    "        for i in range(16):\n",
    "            model = residual_block(model, 3, 64, 1)\n",
    "            \n",
    "        model = Conv2D(filters=64, kernel_size=3, strides=1, padding=\"same\")(model)\n",
    "        model = BatchNormalization(momentum=0.5)(model)\n",
    "        model = add([prev, model])\n",
    "        \n",
    "        \n",
    "        for i in range(2):\n",
    "            model = up_sample_block(model, 3, 256, 1)\n",
    "            \n",
    "        model = Conv2D(filters=3, kernel_size=9, strides=1, padding=\"same\")(model)\n",
    "        model = Activation(\"tanh\")(model)\n",
    "        \n",
    "        return Model(inputs=g_input, outputs=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_block(model, filters, kernel, strides):\n",
    "    \"\"\"Discriminator block.\n",
    "        In -> Conv -> BN -> LReLU -> Out\n",
    "    \"\"\"\n",
    "    \n",
    "    model = Conv2D(filters=filters, kernel_size=kernel, strides=strides, padding=\"same\")(model)\n",
    "    model = BatchNormalization(momentum=0.5)(model)\n",
    "    model = LeakyReLU(alpha=0.2)(model)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator_NN():\n",
    "    \"\"\"The Discriminator Network.\n",
    "        Input -> Conv -> LReLU -> Dis x 7 -> Flatten -> Dense -> LReLU -> Dense -> Sigmoid -> Output\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, image_shape):\n",
    "        self.image_shape = image_shape\n",
    "        \n",
    "    def discriminator(self):\n",
    "        \n",
    "        d_input = Input(shape=self.image_shape)\n",
    "        model = Conv2D(filters=64, kernel_size=3, strides=1, padding=\"same\")(d_input)\n",
    "        model = LeakyReLU(alpha=0.2)(model)\n",
    "        \n",
    "        model = discriminator_block(model, 64, 3, 2)\n",
    "        model = discriminator_block(model, 128, 3, 1)\n",
    "        model = discriminator_block(model, 128, 3, 2)\n",
    "        model = discriminator_block(model, 256, 3, 1)\n",
    "        model = discriminator_block(model, 256, 3, 2)\n",
    "        model = discriminator_block(model, 512, 3, 1)\n",
    "        model = discriminator_block(model, 512, 3, 2)\n",
    "        \n",
    "        model = Flatten()(model)\n",
    "        model = Dense(1024)(model)\n",
    "        model = LeakyReLU(alpha=0.2)(model)\n",
    "        \n",
    "        model = Dense(1)(model)\n",
    "        model = Activation(\"sigmoid\")(model)\n",
    "        \n",
    "        return Model(inputs=d_input, outputs=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "import keras.backend as K\n",
    "\n",
    "class Content_loss():\n",
    "    \n",
    "    def __init__(self, image_shape):\n",
    "        self.image_shape = image_shape\n",
    "        \n",
    "    def content_loss(self, y, y_pred):\n",
    "        vgg19_model = VGG19(include_top=False, weights=\"imagenet\",\n",
    "                          input_shape=self.image_shape)\n",
    "        vgg19_model.trainable = False\n",
    "        for layer in vgg19_model.layers:\n",
    "            layer.trainable = False\n",
    "            \n",
    "        model = Model(inputs=vgg19_model.input, outputs=vgg19_model.get_layer(\"block5_conv4\").output)\n",
    "        model.trainable = False\n",
    "        \n",
    "        return K.mean(K.square(model(y) - model(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GAN_NN(g, d, shape, optimizer, content_loss):\n",
    "    \n",
    "    d.trainable = False\n",
    "    \n",
    "    gan_input = Input(shape=shape)\n",
    "    fake = g(gan_input)\n",
    "    gan_output = d(fake)\n",
    "    \n",
    "    gan_model = Model(inputs = gan_input, outputs=[fake, gan_output])\n",
    "    gan_model.compile(loss=[content_loss, \"binary_crossentropy\"],\n",
    "                     loss_weights=[1., 1e-3], optimizer=optimizer)\n",
    "    \n",
    "    return gan_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Generator Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(e, g, hr_test, lr_test, output_dir=output_dir,\n",
    "                  dim=(1, 3), figsize=(15, 5)):\n",
    "    \n",
    "    hr_batch = np.asarray(hr_test)\n",
    "    lr_batch = np.asarray(lr_test)\n",
    "    sr_batch = np.asarray(g.predict(lr_batch))\n",
    "    \n",
    "    # denormalize\n",
    "    hr_batch = ((hr_batch + 1) * 127.5).astype(np.uint8)\n",
    "    lr_batch = ((lr_batch + 1) * 127.5).astype(np.uint8)\n",
    "    sr_batch = ((sr_batch + 1) * 127.5).astype(np.uint8)\n",
    "    \n",
    "    #ranom sample\n",
    "    idx = random.randint(0, len(hr_test))\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.subplot(dim[0], dim[1], 1)\n",
    "    plt.imshow(lr_batch[idx], interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(dim[0], dim[1], 2)\n",
    "    plt.imshow(sr_batch[idx], interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(dim[0], dim[1], 3)\n",
    "    plt.imshow(hr_batch[idx], interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir + \"result_{}.png\".format(e))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def setup_training(data_dir = data_dir):\n",
    "    if os.path.isdir(model_dir): shutil.rmtree(model_dir)\n",
    "    if os.path.isdir(output_dir): shutil.rmtree(output_dir)\n",
    "    if os.path.isdir(model_dir+\"loss.txt\"): os.remove(model_dir + \"loss.txt\")\n",
    "        \n",
    "    os.mkdir(model_dir)\n",
    "    os.mkdir(output_dir)\n",
    "    loss_file = open(model_dir+\"loss.txt\", \"w+\")\n",
    "    loss_file.close()\n",
    "    \n",
    "    \n",
    "setup_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SRGAN(epochs=epochs, batch_size=batch_size, split_ratio=split_ratio,\n",
    "         sample_every = sample_every, save_every=save_every,\n",
    "         shape=image_shape, scale=down_scale, num_imgs=num_images,\n",
    "         lr=learning_rate, epsilon=epsilon):\n",
    "    \n",
    "    hr_train, hr_test, lr_train, lr_test = load_train_data()\n",
    "    \n",
    "    num_batches = int(len(hr_train)//batch_size)\n",
    "    shape_small = (shape[0]//scale, shape[1]//scale, shape[2])\n",
    "    \n",
    "    g_loss = Content_loss(shape)\n",
    "    optimizer = Adam(lr=learning_rate, epsilon=epsilon)\n",
    "    \n",
    "    g = Generator_NN(shape_small).generator()\n",
    "    d = Discriminator_NN(shape).discriminator()\n",
    "    \n",
    "    g.compile(loss=g_loss.content_loss, optimizer=optimizer)\n",
    "    d.compile(loss=\"binary_crossentropy\", optimizer=optimizer)\n",
    "    \n",
    "    gan = GAN_NN(g, d, shape_small, optimizer, g_loss.content_loss)\n",
    "    \n",
    "    for e in range(1, epochs+1):\n",
    "        for _ in tqdm(range(num_batches)):\n",
    "            idxs = random.randint(0, len(hr_train), size=batch_size)\n",
    "            hr_batch = []\n",
    "            lr_batch = []\n",
    "            hr_batch = [np.array(hr_train[i]) for i in idxs]\n",
    "            hr_batch = np.array(hr_batch)\n",
    "            #hr_batch = np.asarray(hr_batch).reshape(batch_size, shape[0], shape[1], shape[2])\n",
    "            lr_batch = [np.array(lr_train[i]) for i in idxs]\n",
    "            lr_batch = np.array(lr_batch)\n",
    "            #lr_batch = np.asarray(lr_batch).reshape(batch_size, small_shape[0], small_shape[1], small_shape[2])\n",
    "            #print(lr_batch.shape)\n",
    "            sr_batch = g.predict(lr_batch)\n",
    "            print(sr_batch.shape)\n",
    "            # std = 0.05, mean =0.9\n",
    "            real_label = 0.05*random.randn(batch_size) + 0.9\n",
    "            # std = 0.05, mean = 0.1\n",
    "            fake_label = 0.05*random.randn(batch_size) + 0.1\n",
    "            \n",
    "            d.trainable = True\n",
    "            d_loss_real = d.train_on_batch(hr_batch, real_label)\n",
    "            d_loss_fake = d.train_on_batch(sr_batch, fake_label)\n",
    "            d_loss = np.add(d_loss_real, d_loss_fake) / 2.0\n",
    "            d.trainable = False\n",
    "            \n",
    "            idxs = random.randint(0, len(hr_train), size=batch_size)\n",
    "            hr_batch = []\n",
    "            lr_batch = []\n",
    "            hr_batch = [hr_train[i] for i in idxs]\n",
    "            hr_batch = np.asarray(hr_batch)\n",
    "            lr_batch = [lr_train[i] for i in idxs]\n",
    "            lr_batch = np.asarray(lr_batch)\n",
    "            sr_batch = g.predict(lr_batch)\n",
    "            \n",
    "            # std = 0.05, mean = 0.9\n",
    "            gan_label = 0.05*random.randn(batch_size) + 0.9\n",
    "            \n",
    "            gan_loss = gan.train_on_batch(lr_batch, [hr_batch, gan_label])\n",
    "            \n",
    "        print(\"EPOCH {}\\td_loss {}\\tgan_loss {}\".format(e, d_loss, gan_loss))\n",
    "        \n",
    "        loss_file = open(model_dir + \"loss.txt\", \"a\")\n",
    "        loss_file.write(\"EPOCH {}\\td_loss {}\\tgan_loss {}\\n\".format(e, d_loss, str(gan_loss)))\n",
    "        loss_file.close()\n",
    "        \n",
    "        if (e==1) or (e%sample_every==0):\n",
    "            generate_image(e, g, hr_test, lr_test)\n",
    "        if (e%save_every ==0):\n",
    "            g.save(model_dir + \"g_model{}.h5\".format(e))\n",
    "            d.save(model_dir + \"d_model{}.h5\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRGAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_result(output_dir = output_dir):\n",
    "    \n",
    "    images_shown = []\n",
    "    for file_name in os.listdir(output_dir):\n",
    "        name, ext = file_name.split(\".\")\n",
    "        if(int(name)/25 == 0):\n",
    "            image = np.asarray(Image.open(file_name))\n",
    "            images_shown.appned(image)\n",
    "            \n",
    "        fig, ax = plt.subplots(1, len(images_shown))\n",
    "        for img in range(len(image_shown)):\n",
    "            ax[img].set_title(\"sample \"+str(img+1))\n",
    "            ax[img].imshow(images_shown[img])\n",
    "            \n",
    "        \n",
    "visualize_result()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
